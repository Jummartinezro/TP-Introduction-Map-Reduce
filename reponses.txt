--------- 1.1 ExÃ©cution locale
1 - 
 Map input records : nombre de lignes dans le fichier en entrÃ©e
 Map output records : nombre total des occurences calculÃ©es au cours du Map
2 -
Map output records et Reduce input records :
Le rÃ©sultats de la phase du Map est l'entrÃ©e de la phase du Reduce
3 -
Reduce input groups : c'est le nombre de groupes trouvÃ©s lors de la combinaison des clÃ©s resultant de la phase Map


--------- 1.2 Premier contact avec HDFS
quel est le chemin, dans HDFS, vers votre rÃ©pertoire personel ?
/user/elhaddam
/user/martijua


--------- 1.3 - ExÃ©cution sur le cluster
Le compteur de nombre de splits correspand au nombre de dÃ©coupes du fichier en entrÃ©e et qui est repartie sur les jobs.

--------- 1.4 - Combiner et nombre de reducers
1. Quelle est la diÃ©rence entre le rÃ©pertoire de rÃ©sultats obtenu ici, et celui de la partie 1.3 ?
Pourquoi ?
La diffÃ©rence est au niveau de "Launched reduce tasks" 
-Launched reduce tasks=3 pour cette execution
-Launched reduce tasks=1 pour la premiÃ¨re execution
avec une diffÃ©rence sur les access au blocks
Data-local map tasks=3 contre Data-local map tasks=4
Rack-local map tasks=2 contre Rack-local map tasks=1 

2. Quels compteurs permettent de vÃ©rier que le combiner a fonctionnÃ© ?
C'est les compteurs :
Combine input records=421739
Combine output records=85301 

3. Quels compteurs permettent d'estimer le gain eectivement apportÃ© par le combiner ? Com-
parez aux valeurs obtenues sans combiner pour justier votre rÃ©ponse.

C'est le compteur :Spilled Records
sans combiner : 843478
avec combiner : 170602

le faite d'utiliser le combiner reduit les resultats Ã  traitÃ©s par le Reduce et du coups il reduit le nombre de donnÃ©e ecrits sur disque lorsque la taille de donnÃ©es dÃ©passe la taille du buffer clÃ©/valeur.

-------------- 2 - Top-tags Flickr par pays, avec tri en mÃ©moire -------------------------

2.1 Pour pouvoir utiliser un combiner, quel devrait eÌ‚tre le type des donneÌes intermeÌdiaires ? Donnez le type seÌmantique (que repreÌsentent ces cleÌs-valeurs ?) et le type Java.

Au debut de lâ€™expÃ©rience, le combiner aura comme entrÃ©e la mÃªme sortie que celle du mapper. Câ€™est-Ã -dire une clÃ© <Text,Text> reprÃ©sentant le nom du pays et un tag associÃ©. Comme sortie il devrait avoir aussi la mÃªme sortie reÃ§ue par le reducer: une clÃ© <Text,StringAndInt> reprÃ©sentant le nom du pays et le tag avec le nombre dâ€™occurrences.

2.2 Dans le reducer, nous avons une structure en meÌmoire dont la taille deÌpend du nombre de tags distincts : on ne le connaiÌ‚t pas a priori, et il y en a potentiellement beaucoup. Est-ce un probleÌ€me ?

AprÃ¨s lâ€™expÃ©rience, nous avons nous rendu compte que sâ€™il y a beaucoup de donnÃ©es, alors Hadoop va utiliser le combiner. Par contre, quand il y en a pas beaucoup, Hadoop ne lâ€™utilise pas. Comme la sortie du combiner et la sortie du reducer ne sont pas les mÃªmes, alors il y aura un problÃ¨me.

Pour cette raison la sortie du mapper et la sortie du reducer devront Ãªtre les mÃªmes. AprÃ¨s lâ€™expÃ©rience, nous avons les types dâ€™entrÃ©e-sortie suivants:

Mapper:		<LongWritable, Text, Text,StringAndInt>
Combiner: 	<Text, StringAndInt, Text,StringAndInt>
Reducer: 	<Text, StringAndInt, Text,StringAndInt>

-------------- 3 Top-tags Flickr par pays, avec tri par Hadoop -------------------------

Question preÌliminaire : speÌciô°…ez les 2 jobs neÌcessaires (le second va utiliser le reÌsultat du premier), en preÌcisant le type des cleÌs/valeurs en entreÌe, sortie et inteÌrmeÌdiaires. Pour le second, speÌciô°…ez aussi les comparateurs aÌ€ utiliser pour le tri et pour le deÌcoupage en groupes.

EntrÃ©e: 	(Pays,Tag)
Intermediaire:	((Pays,Nombre),Tag)
Sortie:		(Pays, Nombre, Tag)




Le premier job consist Ã  grouper en utilisant Job.setGroupingComparatorClass(Class). En suite on fait le tri en utilisant Job.setSortComparatorClass(Class).