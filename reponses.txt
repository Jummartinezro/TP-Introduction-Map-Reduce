--------- 1.1 ExÃ©cution locale
1 - 
 Map input records : nombre de lignes dans le fichier en entrÃ©e
 Map output records : nombre total des occurences calculÃ©es au cours du Map
2 -
Map output records et Reduce input records :
Le rÃ©sultats de la phase du Map est l'entrÃ©e de la phase du Reduce
3 -
Reduce input groups : c'est le nombre de groupes trouvÃ©s lors de la combinaison des clÃ©s resultant de la phase Map


--------- 1.2 Premier contact avec HDFS
quel est le chemin, dans HDFS, vers votre rÃ©pertoire personel ?
/user/elhaddam
/user/martijua


--------- 1.3 - ExÃ©cution sur le cluster
Le compteur de nombre de splits correspand au nombre de dÃ©coupes du fichier en entrÃ©e et qui est repartie sur les jobs.

--------- 1.4 - Combiner et nombre de reducers
1. Quelle est la diÃ©rence entre le rÃ©pertoire de rÃ©sultats obtenu ici, et celui de la partie 1.3 ?
Pourquoi ?
La diffÃ©rence est au niveau de "Launched reduce tasks" 
-Launched reduce tasks=3 pour cette execution
-Launched reduce tasks=1 pour la premiÃ¨re execution
avec une diffÃ©rence sur les access au blocks
Data-local map tasks=3 contre Data-local map tasks=4
Rack-local map tasks=2 contre Rack-local map tasks=1 

2. Quels compteurs permettent de vÃ©rier que le combiner a fonctionnÃ© ?
C'est les compteurs :
Combine input records=421739
Combine output records=85301 

3. Quels compteurs permettent d'estimer le gain eectivement apportÃ© par le combiner ? Com-
parez aux valeurs obtenues sans combiner pour justier votre rÃ©ponse.

C'est le compteur :Spilled Records
sans combiner : 843478
avec combiner : 170602

le faite d'utiliser le combiner reduit les resultats Ã  traitÃ©s par le Reduce et du coups il reduit le nombre de donnÃ©e ecrits sur disque lorsque la taille de donnÃ©es dÃ©passe la taille du buffer clÃ©/valeur.

-------------- 2 - Top-tags Flickr par pays, avec tri en mÃ©moire -------------------------

2.1 Pour pouvoir utiliser un combiner, quel devrait eÌ‚tre le type des donneÌes intermeÌdiaires ? Donnez le type seÌmantique (que repreÌsentent ces cleÌs-valeurs ?) et le type Java.

Au debut de lâ€™expÃ©rience, le combiner aura comme entrÃ©e la mÃªme sortie que celle du mapper. Câ€™est-Ã -dire une clÃ© <Text,Text> reprÃ©sentant le nom du pays et un tag associÃ©. Comme sortie il devrait avoir aussi la mÃªme sortie reÃ§ue par le reducer: une clÃ© <Text,StringAndInt> reprÃ©sentant le nom du pays et le tag avec le nombre dâ€™occurrences.

2.2 Dans le reducer, nous avons une structure en meÌmoire dont la taille deÌpend du nombre de tags distincts : on ne le connaiÌ‚t pas a priori, et il y en a potentiellement beaucoup. Est-ce un probleÌ€me ?

AprÃ¨s lâ€™expÃ©rience, nous avons nous rendu compte que sâ€™il y a beaucoup de donnÃ©es, alors Hadoop va utiliser le combiner. Par contre, quand il y en a pas beaucoup, Hadoop ne lâ€™utilise pas. Comme la sortie du combiner et la sortie du reducer ne sont pas les mÃªmes, alors il y aura un problÃ¨me.

Pour cette raison la sortie du mapper et la sortie du reducer devront Ãªtre les mÃªmes. AprÃ¨s lâ€™expÃ©rience, nous avons les types dâ€™entrÃ©e-sortie suivants:

Mapper:		<LongWritable, Text, Text,StringAndInt>
Combiner: 	<Text, StringAndInt, Text,StringAndInt>
Reducer: 	<Text, StringAndInt, Text,StringAndInt>

-------------- 3 Top-tags Flickr par pays, avec tri par Hadoop -------------------------

Question preÌliminaire : speÌciô°…fiez les 2 jobs neÌcessaires (le second va utiliser le reÌsultat du premier), en preÌcisant le type des cleÌs/valeurs en entreÌe, sortie et inteÌrmeÌdiaires. Pour le second, speÌcifiô°…ez aussi les comparateurs aÌ€ utiliser pour le tri et pour le deÌcoupage en groupes.

Premier Job:
	Mapper:		<LongWritable, Text, Text,Text> 
			EntrÃ©e: Le Text
			Sortie: (Pays, Tag) comptÃ© 1 fois

	Reducer:	<Text, Text, Text,Int>
			EntrÃ©e: (Pays,Tag), 1 fois
			Sortie: (Pays,Tag), Nb fois
DeuxiÃ¨me Job:		
	Mapper:		<Text, Int, StringAndInt, Text> 
			EntrÃ©e: (Pays,Tag), Nb fois
			Sortie: (Pays,Nb fois), Tag

	Intermediaire:	<StringAndInt, Text, StringAndInt, Text> 
			EntrÃ©e: (Pays,Nb fois), Tag
			Sortie: (Pays,Nb fois), Tag (Mais organisÃ© par groupes (Pays,Nb fois))
			(Le comparateur est le clÃ© (Pays,Nb fois))

	Reducer:	<StringAndInt, Text, StringAndInt,Text>
			EntrÃ©e: (Pays,Nb fois), Tag
			Sortie: (Pays,Nb fois), Tag

3.1. Un avantage de cette meÌthode est que le tri est reÌaliseÌ sur le disque dur des data nodes, plutoÌ‚t qu'en meÌmoire : on peut donc trier des quantiteÌs de donneÌes plus importantes. Dans notre application, cette meÌthode preÌsente un autre avantage pour la fonction reduce ô°…finale; lequel ?



3.1.2. Sâ€™il existe des tags classeÌs ex aequo dans le top-K d'un pays, a-t-on la garantie d'obtenir toujours le meÌ‚me reÌsultat d'une eÌxeÌcution aÌ€ l'autre ? Pourquoi ?



3.2.1. Le ô°…chier complet peÌ€se 44.4 Go, et nous utilisons des blocs de 64Mo. Avec combien de machines le premier map sera le plus rapide possible ?


3.2.2. Une fois que nous utilisons ce partitioner, le deuxieÌ€me job geÌneÌ€re-t-il des transferts de donneÌes sur le reÌseau ? Pourquoi ?


3.2.3. En pratique : si les deux jobs utilisent job.setNumReduceTasks(3), d'apreÌ€s les compteurs que se passe-t-il ?


