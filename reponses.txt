--------- 1.1 Exécution locale
1 - 
 Map input records : nombre de lignes dans le fichier en entrée
 Map output records : nombre total des occurences calculées au cours du Map
2 -
Map output records et Reduce input records :
Le résultats de la phase du Map est l'entrée de la phase du Reduce
3 -
Reduce input groups : c'est le nombre de groupes trouvés lors de la combinaison des clés resultant de la phase Map


--------- 1.2 Premier contact avec HDFS
quel est le chemin, dans HDFS, vers votre répertoire personel ?
/user/elhaddam
/user/martijua


--------- 1.3 - Exécution sur le cluster
Le compteur de nombre de splits correspand au nombre de découpes du fichier en entrée et qui est repartie sur les jobs.

--------- 1.4 - Combiner et nombre de reducers
1. Quelle est la diérence entre le répertoire de résultats obtenu ici, et celui de la partie 1.3 ?
Pourquoi ?
La différence est au niveau de "Launched reduce tasks" 
-Launched reduce tasks=3 pour cette execution
-Launched reduce tasks=1 pour la première execution
avec une différence sur les access au blocks
Data-local map tasks=3 contre Data-local map tasks=4
Rack-local map tasks=2 contre Rack-local map tasks=1 

2. Quels compteurs permettent de vérier que le combiner a fonctionné ?
C'est les compteurs :
Combine input records=421739
Combine output records=85301 

3. Quels compteurs permettent d'estimer le gain eectivement apporté par le combiner ? Com-
parez aux valeurs obtenues sans combiner pour justier votre réponse.

C'est le compteur :Spilled Records
sans combiner : 843478
avec combiner : 170602

le faite d'utiliser le combiner reduit les resultats à traités par le Reduce et du coups il reduit le nombre de donnée ecrits sur disque lorsque la taille de données dépasse la taille du buffer clé/valeur.

-------------- 2 - Top-tags Flickr par pays, avec tri en mémoire -------------------------

2.1 Pour pouvoir utiliser un combiner, quel devrait être le type des données intermédiaires ? Donnez le type sémantique (que représentent ces clés-valeurs ?) et le type Java.

Au debut de l’expérience, le combiner aura comme entrée la même sortie que celle du mapper. C’est-à-dire une clé <Text,Text> représentant le nom du pays et un tag associé. Comme sortie il devrait avoir aussi la même sortie reçue par le reducer: une clé <Text,StringAndInt> représentant le nom du pays et le tag avec le nombre d’occurrences.

2.2 Dans le reducer, nous avons une structure en mémoire dont la taille dépend du nombre de tags distincts : on ne le connaît pas a priori, et il y en a potentiellement beaucoup. Est-ce un problème ?

Après l’expérience, nous avons nous rendu compte que s’il y a beaucoup de données, alors Hadoop va utiliser le combiner. Par contre, quand il y en a pas beaucoup, Hadoop ne l’utilise pas. Comme la sortie du combiner et la sortie du reducer ne sont pas les mêmes, alors il y aura un problème.

Pour cette raison la sortie du mapper et la sortie du reducer devront être les mêmes. Après l’expérience, nous avons les types d’entrée-sortie suivants:

Mapper:		<LongWritable, Text, Text,StringAndInt>
Combiner: 	<Text, StringAndInt, Text,StringAndInt>
Reducer: 	<Text, StringAndInt, Text,StringAndInt>

-------------- 3 Top-tags Flickr par pays, avec tri par Hadoop -------------------------

Question préliminaire : spéci􏰅ez les 2 jobs nécessaires (le second va utiliser le résultat du premier), en précisant le type des clés/valeurs en entrée, sortie et intérmédiaires. Pour le second, spéci􏰅ez aussi les comparateurs à utiliser pour le tri et pour le découpage en groupes.

Entrée: 	(Pays,Tag)
Intermediaire:	((Pays,Nombre),Tag)
Sortie:		(Pays, Nombre, Tag)




Le premier job consist à grouper en utilisant Job.setGroupingComparatorClass(Class). En suite on fait le tri en utilisant Job.setSortComparatorClass(Class).